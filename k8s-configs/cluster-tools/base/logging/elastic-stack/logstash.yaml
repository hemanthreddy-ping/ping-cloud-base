---
apiVersion: v1
kind: ConfigMap
metadata:
  name: enrichment-logstash-config
  labels:
    app: logstash-elastic
data:
  containers.conf: |
    input {
      http {
        port => 8080
        add_field => { "log_type" => "json" }
        add_field => { "log_group" => "application" }
        id => 'containers_log'
        additional_codecs => { "application/json" => "json_lines" }
      }
    }
    filter {
      mutate {
        remove_field => ["date", "headers"]
      }
      mutate {
        replace => {"message" => "%{log}"}
      }
      if ([kubernetes][container_name] == "pingdirectory") {
        if ([log] =~ "/opt/out/instance/logs/access") {
          mutate {
            replace => { "log_type" => "PD_Access_Log" }
            remove_field => "[message]"
          }
        }
      }
      if ([log] =~ "SIEM") {
        if ([kubernetes][container_name] == "pingfederate") {
          if ([log] =~ "System_SIEM") {
            mutate {
              replace => { "log_type" => "PF_System_Log" }
              replace => { "log_group" => "SIEM" }
            }
          } else if ([log] =~ "Audit_SIEM") {
            mutate {
              replace => { "log_type" => "PF_Audit_Log" }
              replace => { "log_group" => "SIEM" }
            }
          } else if ([log] =~ "Provisioner_SIEM") {
            mutate {
              replace => { "log_type" => "PF_Provisioner_Log"}
              replace => { "log_group" => "SIEM" }
            }
          }
        }
        if ([kubernetes][container_name] == "pingaccess") {
          if ([log] =~ "System_SIEM") {
            mutate {
              replace => { "log_type" => "PA_System_Log" }
              replace => { "log_group" => "SIEM" }
            }
          }
          else if ([log] =~ "Audit_SIEM") {
            mutate {
              replace => { "log_type" => "PA_Audit_Log" }
              replace => { "log_group" => "SIEM" }
            }
          } 
        }
        if ([kubernetes][container_name] =~ "pingaccess-was") {
          if ([log] =~ "System_SIEM") {
            mutate {
              replace => { "log_type" => "PA_WAS_System_Log" }
              replace => { "log_group" => "SIEM" }
            }
          }
          else if ([log] =~ "Audit_SIEM") {
            mutate {
              replace => { "log_type" => "PA_WAS_Audit_Log" }
              replace => { "log_group" => "SIEM" }
            }
          } 
        }
        if ([kubernetes][container_name] == "pingaccess-admin") {
          if ([log] =~ "System_SIEM") {
            mutate {
              replace => { "log_type" => "PA_Admin_System_Log" }
              replace => { "log_group" => "SIEM" }
            }
          }
          else if ([log] =~ "Audit_SIEM") {
            mutate {
              replace => { "log_type" => "PA_Admin_Audit_Log" }
              replace => { "log_group" => "SIEM" }
            }
          } 
        }
        if ([kubernetes][container_name] == "pingaccess-was-admin") {
          if ([log] =~ "System_SIEM") {
            mutate {
              replace => { "log_type" => "PA_WAS_Admin_System_Log" }
              replace => { "log_group" => "SIEM" }
            }
          }
          else if ([log] =~ "Audit_SIEM") {
            mutate {
              replace => { "log_type" => "PA_WAS_Admin_Audit_Log" }
              replace => { "log_group" => "SIEM" }
            }
          } 
        }
        if ([kubernetes][container_name] == "pingfederate-admin") {
          if ([log] =~ "System_SIEM") {
            mutate {
              replace => { "log_type" => "PF_Admin_System_Log" }
              replace => { "log_group" => "SIEM" }
            }
          }
          else if ([log] =~ "Audit_SIEM") {
            mutate {
              replace => { "log_type" => "PF_Admin_Audit_Log" }
              replace => { "log_group" => "SIEM" }
            }
          }
          else if ([log] =~ "AdminApiAuditSIEM") {
            mutate {
              replace => { "log_type" => "PF_Admin_Audit_API_Log"}
              replace => { "log_group" => "SIEM" }
            }
          }
          else if ([log] =~ "Provisioner_SIEM") {
            mutate {
              replace => { "log_type" => "PF_Provisioner_Log" }
              replace => { "log_group" => "SIEM" }
            }
          }
        }
      }
      if ([kubernetes][container_name] == "nginx-ingress-controller") {
        mutate {
          replace => { "log_type" => "nginx_log" }
        }
        if [stream] == "stdout" {
          grok {
            match => { "message" => ["%{IPORHOST:[nginx][access][remote_ip]} - %{DATA:[nginx][access][user_name]} \[%{HTTPDATE:[nginx][access][time]}\] \"%{WORD:[nginx][access][method]} %{DATA:[nginx][access][url]} HTTP/%{NUMBER:[nginx][access][http_version]}\" %{NUMBER:[nginx][access][response_code]} %{NUMBER:[nginx][access][body_sent][bytes]} \"%{DATA:[nginx][access][referrer]}\" \"%{DATA:[nginx][access][agent]}\" %{NUMBER:[nginx][access][request_length]} %{NUMBER:[nginx][access][request_time]} \[%{DATA:[nginx][access][proxy_upstream_name]}\] \[%{DATA:[nginx][access][proxy_alternative_upstream_name]}\] %{NOTSPACE:[nginx][access][upstream_addr]} %{NUMBER:[nginx][access][upstream_response_length]} %{NUMBER:[nginx][access][upstream_response_time]} %{NUMBER:[nginx][access][upstream_response_code]} %{NOTSPACE:[nginx][access][req_id]}"] }
            remove_field => "message"
          }
          mutate {
            add_field => { "read_timestamp" => "%{@timestamp}" }
          }
          date {
            match => [ "[nginx][access][time]", "dd/MMM/YYYY:H:m:s Z" ]
            remove_field => "[nginx][access][time]"
          }
          useragent {
            source => "[nginx][access][agent]"
            target => "[nginx][access][user_agent]"
            remove_field => "[nginx][access][agent]"
          }
          geoip {
            source => "[nginx][access][remote_ip]"
            target => "[nginx][access][geoip]"
          }
        }
        else if [stream] == "stderr" {
          if ([log] =~ /[\d\/: ]+\[.+?\]/) {
            grok {
              match => { "message" => ["%{DATA:[nginx][error][time]} \[%{DATA:[nginx][error][level]}\] %{NUMBER:[nginx][error][pid]}#%{NUMBER:[nginx][error][tid]}: (\*%{NUMBER:[nginx][error][connection_id]} )?%{GREEDYDATA:[nginx][error][message]}"] }
              remove_field => "message"
            }
            mutate {
              rename => { "@timestamp" => "read_timestamp" }
            }
            date {
              match => [ "[nginx][error][time]", "YYYY/MM/dd H:m:s" ]
              remove_field => "[nginx][error][time]"
            }
          }
          else if ([log] =~ /\w{5} [\d:\.]{15}.[ \t]+.*?\]/) {
            mutate {
              remove_field => "[message]"
            }
            grok {
              match => { "log" => ["[A-Z]%{DATA:timestamp} [ \t]+%{DATA}\] %{GREEDYDATA:message}"]
              }
            }
            date {
              match => ["timestamp", "MMdd HH:mm:ss.SSSSSS"]
            }
          }
        }
        mutate {
          remove_field => "[log]"
        }
      }
      if ([log_type] == "json") {
        if ([log] =~ /^\/.*\.log/ ) {
          mutate {
            remove_field => "message"
          }
          grok {
            match => {
              log => [ "^\/opt\/out\/instance.*?\/log.*\/%{DATA:log_name}\.log %{GREEDYDATA:message}" ]
            }
          }
          mutate {
            gsub => [
              "message", "\/opt\/out\/instance.*?\/log.*/.*\.log", ""
            ]
            gsub => [
              "message", "\\n", "\n"
            ]
          }
        }
        mutate {
          remove_field => "[log]"
        }
      }
    }

  ping_apps.conf: |
    filter {
        #PROCESS PING FED AUDIT LOG
        #Log4J Pattern Matching from PF and extraction of JSON DATA from the MSG
        if([log_type] == "PF_Audit_Log"){
            grok {
                match => {
                  "log" => [ "<%{NUMBER}>%{DATA:timestamp}  [a-zA-Z-]{1,30}-[0-9]{1,3}[ ,]{1,3}%{GREEDYDATA:json_data}" ]
                }
            }
            mutate {
              gsub => [
                "json_data", "\\n", ""
              ]
            }
            #Convert the injested data into Individual Fields for elasticsearch
            json {
                source => "json_data"
            }
            if([json_data]){
                date {
                  match => ["timestamp", "MMM dd HH:mm:ss"]
                }
                #Drop the original as you do not need it at this point.
                mutate {
                    remove_field => "[json_data]"
                    remove_field => "[log]"
                    remove_field => "[pod_name]"
                    remove_field => "[timestamp]"
                }
                geoip {
                    source => "ip"
                }
                #Security Enrichments begin here, ENRICH THE IP ADDRESS DETAIL
                translate {
                    source => "ip"
                    target => "threat_intel"
                    fallback => "No"
                    dictionary_path => '/enrichment-cache-files/AlienVaultIP.yml'
                    refresh_behaviour => "replace"
                }
                translate {
                    source => "ip"
                    target => "tor_intel"
                    fallback => "No"
                    dictionary_path => '/enrichment-cache-files/TorNodes.yml'
                    refresh_behaviour => "replace"
                }
                translate {
                    source => "[geoip][country_name]"
                    target => "malicious_country"
                    fallback => "No"
                    dictionary_path => '/enrichment-cache-files/MaliciousCountries.yml'
                    refresh_behaviour => "replace"
                }
                translate {
                    source => "[geoip][country_name]"
                    target => "known_country"
                    fallback => "No"
                    dictionary_path => '/enrichment-cache-files/KnownCountries.yml'
                    refresh_behaviour => "replace"
                }
                if([malicious_country] == "No" and [known_country] == "No"){
                    mutate {
                        add_field => { "suspicious_country" => "YES" }
                    }
                }
                #Query for previous logins in Elasticsearch, if login is found append data to the log
                #IF A SUCCESSFUL LOGIN OCCURS, Query ES to see if the the attempt was successful in the past to determine distance from previous login.
                if([status] == "success" and [event] == "AUTHN_ATTEMPT"){
                    elasticsearch {
                        index => "pf-audit*"
                        query_template => "/etc/logstash/templates/6hr-1200km-template.json"
                        hosts => "${LOGSTASH_ELASTICSEARCH_URL}:${LOGSTASH_ELASTICSEARCH_PORT}"
                        add_field => {"found_distance_alert" => "YES"}
                        fields => {
                            "subject" => "found_subject"
                            "ip" => "found_ip"
                            "[geoip][country_name]" => "found_country"
                            "[geoip][city_name]" => "found_city_name"
                            "[geoip][location][lat]" => "[found_geoip][location][lat]"
                            "[geoip][location][lon]" => "[found_geoip][location][lon]"
                        }
                    }
                }
            }
        }
        # PROCESS PING FED SYSTEM LOG
        # USING LOG4J's ability to output in JSON limits the amount of processing you have to do besides splitting up JSON.
        if([log_type] == "PF_System_Log"){
            grok {
                match => {
                  "log" => [ "<%{NUMBER}>%{DATA:timestamp}  [a-zA-Z-]{1,30}-[0-9]{1,3}[ ,]{1,3}%{GREEDYDATA:json_data}" ]
                }
            }
            json {
                source => "json_data"
            }
            if([json_data]){
                date {
                  match => ["timestamp", "MMM dd HH:mm:ss"]
                }
                mutate {
                    remove_field => "[json_data]"
                    remove_field => "[log]"
                    remove_field => "[pod_name]"
                    remove_field => "[timestamp]"
                }
            }
        }
        
        if([log_type] == "PF_Provisioner_Log"){
            grok {
                match => {
                  "log" => [ "<%{NUMBER}>%{DATA:timestamp}  [a-zA-Z-]{1,30}-[0-9]{1,3}[ ,]{1,3}%{GREEDYDATA:json_data}" ]
                }
            }
            json {
              source => "json_data"
            }
            if([json_data]) {
              date {
                match => ["timestamp", "MMM dd HH:mm:ss"]
              }
              mutate {
                remove_field => "[json_data]"
                remove_field => "[log]"
                remove_field => "[pod_name]"
                remove_field => "[timestamp]"
              }
            }
        }
        # PROCESS PING DIRECTORY LOGS
        # LOGS ARE SENT IN A CUSTOM FORMAT, AND THIS CONFIG MATCHES AND PARSES THEM.
        if([log_type] == "PD_Access_Log"){
            kv {
                source => "[log]"
                value_split => "="
            }
            grok {
                match => { "log" => "%{WORD:log_name} \[%{GREEDYDATA:timestamp}\] %{WORD:ldapType} %{GREEDYDATA}" }
            }
            date {
              match => ["timestamp", "dd/MMM/yyyy:HH:mm:ss.SSS Z"]
            }
            mutate{
                gsub => [
                    "filter", '"', ""
                ]
                gsub => [
                    "dn", '"', ""
                ]
                gsub => [
                    "requesterIP", "internal", "127.0.0.1"
                ]
            }
            geoip {
                source => "requesterIP"
            }
            translate {
                source => "requesterIP"
                target => "threat_intel"
                fallback => "No"
                dictionary_path => '/enrichment-cache-files/AlienVaultIP.yml'
                refresh_behaviour => "replace"
            }
            translate {
                source => "requesterIP"
                target => "tor_intel"
                fallback => "No"
                dictionary_path => '/enrichment-cache-files/TorNodes.yml'
                refresh_behaviour => "replace"
            }
            translate {
                source => "[geoip][country_name]"
                target => "malicious_country"
                fallback => "No"
                dictionary_path => '/enrichment-cache-files/MaliciousCountries.yml'
                refresh_behaviour => "replace"
            }
            translate {
                source => "[geoip][country_name]"
                target => "known_country"
                fallback => "No"
                dictionary_path => '/enrichment-cache-files/KnownCountries.yml'
                refresh_behaviour => "replace"
            }
            if([malicious_country] == "No" and [known_country] == "No"){
                mutate {
                    add_field => { "suspicious_country" => "YES" }
                }
            }
            mutate {
                remove_field => "[log]"
                remove_field => "[tags]"
            }
        }
        # PROCESS PING ACCESS AUDIT LOG
        # PING ACCESS IS SENDING IN LOG4J FORMAT (JSON), SO PARSING IS MUCH LIKE PING FED.
        if([log_type] == "PA_Audit_Log" or [log_type] == "PA_WAS_Audit_Log"){
            grok {
                match => {
                    "message" => [ "<%{NUMBER}>%{DATA:timestamp}  [a-zA-Z-]{1,30}-[0-9]{1,3}[ ,]{1,3}%{GREEDYDATA:json_data}" ]
                }
            }
            json {
                source => "json_data"
            }
            if([json_data]){ 
                date {
                  match => ["timestamp", "MMM dd HH:mm:ss"]
                }
                mutate {
                    remove_field => "[json_data]" 
                    remove_field => "[timestamp]"
                }
                geoip {
                    source => "client"
                }
                translate {
                    source => "client"
                    target => "threat_intel"
                    fallback => "No"
                    dictionary_path => '/enrichment-cache-files/AlienVaultIP.yml'
                    refresh_behaviour => "replace"
                }
                translate {
                    source => "client"
                    target => "tor_intel"
                    fallback => "No"
                    dictionary_path => '/enrichment-cache-files/TorNodes.yml'
                    refresh_behaviour => "replace"
                }
                translate {
                    source => "[geoip][country_name]"
                    target => "malicious_country"
                    fallback => "No"
                    dictionary_path => '/enrichment-cache-files/MaliciousCountries.yml'
                    refresh_behaviour => "replace"
                }
                translate {
                    source => "[geoip][country_name]"
                    target => "known_country"
                    fallback => "No"
                    dictionary_path => '/enrichment-cache-files/KnownCountries.yml'
                    refresh_behaviour => "replace"
                }
                if([malicious_country] == "No" and [known_country] == "No"){
                    mutate {
                        add_field => { "suspicious_country" => "YES" }
                    }
                }
            }
        }
        if([log_type] == "PA_System_Log" or [log_type] == "PA_WAS_System_Log"){
            grok {
                match => {
                    "message" => [ "<%{NUMBER}>%{DATA:timestamp}  [a-zA-Z-]{1,30}-[0-9]{1,3}[ ,]{1,3}%{GREEDYDATA:json_data}" ]
                }
            }
            json {
                source => "json_data"
            }
            if([json_data]){
                date {
                  match => ["timestamp", "MMM dd HH:mm:ss"]
                }
                mutate {
                    remove_field => "[json_data]"
                    remove_field => "[log]"
                    remove_field => "[pod_name]"
                    remove_field => "[timestamp]"
                }
            }
        }
        if([log_type] == "PA_Admin_System_Log" or [log_type] == "PA_WAS_Admin_System_Log"){
            grok {
                match => {
                    "message" => [ "<%{NUMBER}>%{DATA:timestamp}  [a-zA-Z-]{1,30}-[0-9]{1,3}[ ,]{1,3}%{GREEDYDATA:json_data}" ]
                }
            }
            json {
                source => "json_data"
            }
            if([json_data]){
                date {
                  match => ["timestamp", "MMM dd HH:mm:ss"]
                }
                mutate {
                    remove_field => "[json_data]"
                    remove_field => "[log]"
                    remove_field => "[pod_name]"
                    remove_field => "[timestamp]"
                }
            }
        }
        if([log_type] == "PF_Admin_System_Log"){
            grok {
                match => {
                    "message" => [ "<%{NUMBER}>%{DATA:timestamp}  [a-zA-Z-]{1,30}-[0-9]{1,3}[ ,]{1,3}%{GREEDYDATA:json_data}" ]
                }
            }
            json {
                source => "json_data"
            }
            if([json_data]){
                date {
                  match => ["timestamp", "MMM dd HH:mm:ss"]
                }
                mutate {
                    remove_field => "[json_data]"
                    remove_field => "[log]"
                    remove_field => "[pod_name]"
                    remove_field => "[timestamp]"
                }
            }
        }
        if([log_type] == "PA_Admin_Audit_Log" or [log_type] == "PA_WAS_Admin_Audit_Log"){
            grok {
                match => {
                    "message" => [ "<%{NUMBER}>%{DATA:timestamp}  [a-zA-Z-]{1,30}-[0-9]{1,3}[ ,]{1,3}%{GREEDYDATA:json_data}" ]
                }
            }
            json {
                source => "json_data"
            }
            if([json_data]){
                date {
                  match => ["timestamp", "MMM dd HH:mm:ss"]
                }
                mutate {
                    remove_field => "[json_data]"
                    remove_field => "[log]"
                    remove_field => "[pod_name]"
                    remove_field => "[timestamp]"
                }
            }
        }
        if([log_type] == "PF_Admin_Audit_Log" or [log_type] == "PF_Admin_Audit_API_Log" ){
            grok {
                match => {
                    "message" => [ "<%{NUMBER}>%{DATA:timestamp}  [a-zA-Z-]{1,30}-[0-9]{1,3}[ ,]{1,3}%{GREEDYDATA:json_data}" ]
                }
            }
            json {
                source => "json_data"
            }
            if([json_data]){
                date {
                  match => ["timestamp", "MMM dd HH:mm:ss"]
                }
                mutate {
                    remove_field => "[json_data]"
                    remove_field => "[log]"
                    remove_field => "[pod_name]"
                    remove_field => "[timestamp]"
                }
            }
        }
    }

    output {
        if ([log_group] == "application") {
          elasticsearch {
            hosts => "${LOGSTASH_ELASTICSEARCH_URL}:${LOGSTASH_ELASTICSEARCH_PORT}"
            sniffing => false
            ilm_enabled => true
            ilm_rollover_alias => "logstash"
            ilm_policy => "ping-logstash-policy"
          }
        }
        if([log_type] == "PF_Provisioner_Log"){
            elasticsearch {
                id => "pf_provision_out"
                hosts => "${LOGSTASH_ELASTICSEARCH_URL}:${LOGSTASH_ELASTICSEARCH_PORT}"
                ilm_enabled => true
                ilm_rollover_alias => "pf-provision"
                ilm_policy => "ping-2-day-retention"
            }
        }
        if([log_type] == "PF_Audit_Log"){
            elasticsearch {
                id => "pf_audit_out"
                hosts => "${LOGSTASH_ELASTICSEARCH_URL}:${LOGSTASH_ELASTICSEARCH_PORT}"
                ilm_enabled => true
                ilm_rollover_alias => "pf-audit"
                ilm_policy => "ping-2-day-retention"
            }
        }
        if([log_type] == "PF_System_Log"){
            elasticsearch {
                id => "pf_system_out"
                hosts => "${LOGSTASH_ELASTICSEARCH_URL}:${LOGSTASH_ELASTICSEARCH_PORT}"
                ilm_enabled => true
                ilm_rollover_alias => "pf-system"
                ilm_policy => "ping-2-day-retention"
            }
        }
        if([log_type] == "PD_Access_Log"){
          elasticsearch {
            id => "pd_out"
            hosts => "${LOGSTASH_ELASTICSEARCH_URL}:${LOGSTASH_ELASTICSEARCH_PORT}"
            ilm_enabled => true
            ilm_rollover_alias => "pd-access"
            ilm_policy => "ping-2-day-retention"
          }
      }
      if([log_type] == "PD_Failed_Ops"){
        elasticsearch {
            id => "pd_failed_ops_out"
            hosts => "${LOGSTASH_ELASTICSEARCH_URL}:${LOGSTASH_ELASTICSEARCH_PORT}"
            ilm_enabled => true
            ilm_rollover_alias => "pd-failed-ops"
            ilm_policy => "ping-2-day-retention"
        }
      }
      if([log_type] == "PA_System_Log"){
        elasticsearch {
          id => "pa_system_out"
          hosts => "${LOGSTASH_ELASTICSEARCH_URL}:${LOGSTASH_ELASTICSEARCH_PORT}"
          ilm_enabled => true
          ilm_rollover_alias => "pa-system"
          ilm_policy => "ping-2-day-retention"
        }
      }
      if([log_type] == "PA_Audit_Log"){
        elasticsearch {
          id => "pa_audit_out"
          hosts => "${LOGSTASH_ELASTICSEARCH_URL}:${LOGSTASH_ELASTICSEARCH_PORT}"
          ilm_enabled => true
          ilm_rollover_alias => "pa-audit"
          ilm_policy => "ping-2-day-retention"
        }
      }
      if([log_type] == "PA_WAS_System_Log"){
        elasticsearch {
          id => "pa_was_system_out"
          hosts => "${LOGSTASH_ELASTICSEARCH_URL}:${LOGSTASH_ELASTICSEARCH_PORT}"
          ilm_enabled => true
          ilm_rollover_alias => "pa-was-system"
          ilm_policy => "ping-2-day-retention"
        }
      }
      if([log_type] == "PA_WAS_Audit_Log"){
        elasticsearch {
          id => "pa_was_audit_out"
          hosts => "${LOGSTASH_ELASTICSEARCH_URL}:${LOGSTASH_ELASTICSEARCH_PORT}"
          ilm_enabled => true
          ilm_rollover_alias => "pa-was-audit"
          ilm_policy => "ping-2-day-retention"
        }
      }
      if([log_type] == "PF_Admin_Audit_Log" or [log_type] == "PF_Admin_Audit_API_Log"){
          elasticsearch {
              id => "pf_admin_audit_out"
              hosts => "${LOGSTASH_ELASTICSEARCH_URL}:${LOGSTASH_ELASTICSEARCH_PORT}"
              ilm_enabled => true
              ilm_rollover_alias => "pf-admin-audit"
              ilm_policy => "ping-2-day-retention"
          }
      }
      if([log_type] == "PF_Admin_System_Log"){
          elasticsearch {
              id => "pf_admin_system_out"
              hosts => "${LOGSTASH_ELASTICSEARCH_URL}:${LOGSTASH_ELASTICSEARCH_PORT}"
              ilm_enabled => true
              ilm_rollover_alias => "pf-admin-system"
              ilm_policy => "ping-2-day-retention"
          }
      }
      if([log_type] == "PA_Admin_System_Log"){
        elasticsearch {
          id => "pa_admin_system_out"
          hosts => "${LOGSTASH_ELASTICSEARCH_URL}:${LOGSTASH_ELASTICSEARCH_PORT}"
          ilm_enabled => true
          ilm_rollover_alias => "pa-admin-system"
          ilm_policy => "ping-2-day-retention"
        }
      }
      if([log_type] == "PA_Admin_Audit_Log"){
        elasticsearch {
          id => "pa_admin_audit_out"
          hosts => "${LOGSTASH_ELASTICSEARCH_URL}:${LOGSTASH_ELASTICSEARCH_PORT}"
          ilm_enabled => true
          ilm_rollover_alias => "pa-admin-audit"
          ilm_policy => "ping-2-day-retention"
        }
      }
      if([log_type] == "PA_WAS_Admin_System_Log"){
        elasticsearch {
          id => "pa_was_admin_system_out"
          hosts => "${LOGSTASH_ELASTICSEARCH_URL}:${LOGSTASH_ELASTICSEARCH_PORT}"
          ilm_enabled => true
          ilm_rollover_alias => "pa-was-admin-system"
          ilm_policy => "ping-2-day-retention"
        }
      }
      if([log_type] == "PA_WAS_Admin_Audit_Log"){
        elasticsearch {
          id => "pa_was_admin_audit_out"
          hosts => "${LOGSTASH_ELASTICSEARCH_URL}:${LOGSTASH_ELASTICSEARCH_PORT}"
          ilm_enabled => true
          ilm_rollover_alias => "pa-was-admin-audit"
          ilm_policy => "ping-2-day-retention"
        }
      }
    }

---
apiVersion: apps/v1
kind: Deployment 
metadata:
  name: logstash-elastic
  labels:
    app: logstash-elastic
spec:
  replicas: 2
  selector:
    matchLabels:
      app: logstash-elastic
  template:
    metadata:
      labels:
        app: logstash-elastic
    spec:
      serviceAccount: logstash-elastic
      initContainers:

      - name: check-service-availability
        image: public.ecr.aws/r2h3l6e4/pingcloud-monitoring/enrichment-bootstrap:3.14-v1.2.1
        imagePullPolicy: IfNotPresent
        command: ["sh", '$(CONTAINER_NAME).sh']

        env:
        - name: CONTAINER_NAME
          value: "check-service-availability"

        - name: CHECK_SERVICE_URL
          value: "http://elasticsearch"
        - name: CHECK_SERVICE_PORT
          value: "9200"
        - name: DESIRED_STATUS
          value: "green"

      - name: create-enrichment-cache-files
        image: public.ecr.aws/r2h3l6e4/pingcloud-monitoring/enrichment-bootstrap:3.14-v1.2.1
        
        imagePullPolicy: IfNotPresent
        workingDir: /scripts
        command: ["sh", '$(CONTAINER_NAME).sh']

        env:
        - name: CONTAINER_NAME
          value: "create-enrichment-cache-files"
        - name:  ENRICHMENT_TOR_FEED_URL
          value: "https://check.torproject.org/exit-addresses"
        - name:  ENRICHMENT_ALIEN_VAULT_FEED_URL
          value: "https://reputation.alienvault.com/reputation.generic"
        - name:  ENRICHMENT_FILEPATH
          value: "/enrichment-cache-files/"
        - name:  PYTHONUNBUFFERED
          value: "1"
        - name: PYTHONIOENCODING
          value: "UTF-8"

        volumeMounts:
        - name: enrichment-cache
          mountPath: /enrichment-cache
        - name: enrichment-cache-files
          mountPath: /enrichment-cache-files

      containers:
      - name: logstash
        image: public.ecr.aws/r2h3l6e4/pingcloud-monitoring/logstash:8.1.3-v1.0.0
        imagePullPolicy: IfNotPresent
        securityContext:
          runAsUser: 1000
          runAsGroup: 1000
        env:
          - name: CONTAINER_NAME
            value: "logstash"
          - name: LS_JAVA_OPTS
            value: "-Xmx1g -Xms1g"
          - name: NODE_NAME
            valueFrom:
              fieldRef:
                fieldPath: spec.nodeName
          - name: LOGSTASH_ELASTICSEARCH_URL
            value: "http://elasticsearch"
          - name: LOGSTASH_ELASTICSEARCH_PORT
            value: "9200"
          - name: CONFIG_RELOAD_AUTOMATIC
            value: "true"
          - name: CONFIG_RELOAD_INTERVAL
            value: "5s"
          - name: LOG_FORMAT
            value: "json"
          - name: LOG_LEVEL
            value: "warn"
          - name: PIPELINE_BATCH_DELAY
            value: "500"
          - name: PIPELINE_BATCH_SIZE
            value: "1500"
          - name: PIPELINE_ECS_COMPATIBILITY
            value: "disabled"
          - name: XPACK_MONITORING_ENABLED
            value: "true"
          - name: PIPELINE_ORDERED
            value: "false"
          - name: QUEUE_TYPE
            value: "persisted"
        resources:
          limits:
            memory: 4Gi
          requests:
            cpu: 150m
            memory: 1Gi

        ports:
          - containerPort: 9600
            name: rest
            protocol: TCP
          - containerPort: 8080
            name: http-log-input
            protocol: TCP

        volumeMounts:
        - name: enrichment-logstash-config
          mountPath: /usr/share/logstash/pipeline
          readOnly: true
        - name: enrichment-logstash-search-templates
          mountPath: /etc/logstash/templates
          readOnly: true
        - name: enrichment-cache-files
          mountPath: /enrichment-cache-files
          readOnly: false

      # Sidecar enrichment container which updates Logstash dictionaries
      - name: enrichment-sidecar
        image: public.ecr.aws/r2h3l6e4/pingcloud-monitoring/enrichment-bootstrap:3.14-v1.2.1
        
        imagePullPolicy: IfNotPresent
        workingDir: /scripts
        command: ["sh", '$(CONTAINER_NAME).sh']

        env:
        - name: CONTAINER_NAME
          value: "enrichment-sidecar"
        - name:  ENRICHMENT_TOR_FEED_URL
          value: "https://check.torproject.org/exit-addresses"
        - name:  ENRICHMENT_ALIEN_VAULT_FEED_URL
          value: "https://reputation.alienvault.com/reputation.generic"
        - name:  ENRICHMENT_FILEPATH
          value: "/enrichment-cache-files/"
        - name:  ENRICHMENT_DELAY_SECONDS
          value: "600"
        - name:  PYTHONUNBUFFERED
          value: "1"
        - name: PYTHONIOENCODING
          value: "UTF-8"
        
        volumeMounts:
        - name: enrichment-cache-files
          mountPath: /enrichment-cache-files
          readOnly: false

      terminationGracePeriodSeconds: 30

      volumes:
      - name: enrichment-logstash-config
        configMap:
          name: enrichment-logstash-config
      - name: enrichment-logstash-search-templates
        configMap:
          name: enrichment-logstash-search-templates
      - name: enrichment-cache
        configMap:
          name: enrichment-cache
      - name: enrichment-cache-files
        emptyDir: {}

      tolerations:   
      - operator: Exists

---
kind: Service
apiVersion: v1
metadata:
  name: logstash-elastic
  labels:
    app: logstash-elastic
spec:
  selector:
    app: logstash-elastic
  ports:
    - port: 9600
      name: rest
    - port: 8080
      name: http-log-input

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: logstash-elastic
  labels:
    app: logstash-elastic

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: logstash-elastic
  labels:
    app: logstash-elastic
rules:
- apiGroups:
  - ""
  resources:
  - pods
  - namespaces
  verbs:
  - get
  - list
  - watch

---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: logstash-elastic
roleRef:
  kind: ClusterRole
  name: logstash-elastic
  apiGroup: rbac.authorization.k8s.io
subjects:
- kind: ServiceAccount
  name: logstash-elastic
